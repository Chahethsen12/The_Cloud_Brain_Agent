{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMMz72JNHBJ0tQJNPtcWGwc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Chahethsen12/The_Cloud_Brain_Agent/blob/main/The_Cloud_Brain_Agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install Libraries"
      ],
      "metadata": {
        "id": "PaSvw2UxMxpv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zFBtEOOkMe7k",
        "outputId": "096849ad-6f8b-4d03-86d6-2688c7a5c0a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/137.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m137.5/137.5 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hLibraries installed successfully!\n"
          ]
        }
      ],
      "source": [
        "!pip install -q langchain langchain-groq langgraph tavily-python\n",
        "print(\"Libraries installed successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set API Keys"
      ],
      "metadata": {
        "id": "Kg-y3Ek8M4nX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "from getpass import getpass\n",
        "\n",
        "# Enter your keys when prompted.\n",
        "# It keeps them hidden so they don't appear in your code history.\n",
        "os.environ[\"GROQ_API_KEY\"] = getpass(\"Enter your Groq API Key: \")\n",
        "os.environ[\"TAVILY_API_KEY\"] = getpass(\"Enter your Tavily API Key: \")"
      ],
      "metadata": {
        "id": "th6ZPWGlMiW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Agent Code"
      ],
      "metadata": {
        "id": "Fq40KQU9M7qr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Annotated, TypedDict\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.graph.message import add_messages\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "\n",
        "# 1. SETUP TOOLS & MODEL\n",
        "tool = TavilySearchResults(max_results=2)\n",
        "llm = ChatGroq(model=\"llama3-8b-8192\")\n",
        "llm_with_tools = llm.bind_tools([tool])\n",
        "\n",
        "# 2. DEFINE STATE\n",
        "class State(TypedDict):\n",
        "    messages: Annotated[list, add_messages]\n",
        "\n",
        "# 3. DEFINE NODES\n",
        "def chatbot(state: State):\n",
        "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
        "\n",
        "class BasicToolNode:\n",
        "    def __init__(self, tools: list) -> None:\n",
        "        self.tools_by_name = {t.name: t for t in tools}\n",
        "    def __call__(self, inputs: dict):\n",
        "        if messages := inputs.get(\"messages\", []):\n",
        "            message = messages[-1]\n",
        "        else:\n",
        "            raise ValueError(\"No message found\")\n",
        "        outputs = []\n",
        "        for tool_call in message.tool_calls:\n",
        "            tool_result = self.tools_by_name[tool_call[\"name\"]].invoke(tool_call[\"args\"])\n",
        "            outputs.append({\n",
        "                \"tool_call_id\": tool_call[\"id\"],\n",
        "                \"role\": \"tool\",\n",
        "                \"name\": tool_call[\"name\"],\n",
        "                \"content\": str(tool_result)\n",
        "            })\n",
        "        return {\"messages\": outputs}\n",
        "\n",
        "tool_node = BasicToolNode(tools=[tool])\n",
        "\n",
        "# 4. BUILD GRAPH\n",
        "graph_builder = StateGraph(State)\n",
        "graph_builder.add_node(\"chatbot\", chatbot)\n",
        "graph_builder.add_node(\"tools\", tool_node)\n",
        "graph_builder.add_edge(START, \"chatbot\")\n",
        "\n",
        "def route_tools(state: State):\n",
        "    if isinstance(state, list):\n",
        "        ai_message = state[-1]\n",
        "    elif messages := state.get(\"messages\", []):\n",
        "        ai_message = messages[-1]\n",
        "    else:\n",
        "        return END\n",
        "    if hasattr(ai_message, \"tool_calls\") and len(ai_message.tool_calls) > 0:\n",
        "        return \"tools\"\n",
        "    return END\n",
        "\n",
        "graph_builder.add_conditional_edges(\"chatbot\", route_tools, {\"tools\": \"tools\", END: END})\n",
        "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
        "graph = graph_builder.compile()\n",
        "\n",
        "print(\"Agent built successfully! Run the next cell to chat.\")"
      ],
      "metadata": {
        "id": "VOzythWRM_rs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the Chat"
      ],
      "metadata": {
        "id": "4Pi9sr0pNA79"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_input = \"What are the latest updates on OpenAI's o1 model from 2024-2025?\"\n",
        "events = graph.stream({\"messages\": [(\"user\", user_input)]}, stream_mode=\"values\")\n",
        "\n",
        "for event in events:\n",
        "    if \"messages\" in event:\n",
        "        print(f\"ðŸ¤– Agent: {event['messages'][-1].content}\")\n",
        "        print(\"-\" * 50)"
      ],
      "metadata": {
        "id": "oAVE0hy6Mv-Q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}